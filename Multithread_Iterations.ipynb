{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc437ae2bb8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from Stationary.core import *\n",
    "from Stationary.utils import *\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_seed(x):\n",
    "    np.random.seed(x)\n",
    "    torch.manual_seed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, inputSize, outputSize, H = 64):\n",
    "        \n",
    "        super(customModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, H, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.linear3 = torch.nn.Linear(H, H)\n",
    "        self.linear4 = torch.nn.Linear(H, outputSize)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.linear(x))\n",
    "        x = torch.tanh(self.linear2(x))\n",
    "        x = torch.tanh(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----Federated Parameters\n",
    "num_workers = 3\n",
    "num_rounds = 4\n",
    "\n",
    "\n",
    "#-----Linear Regression Parameters\n",
    "m = -2.1\n",
    "m2 = 1.4\n",
    "m3 = -0.5\n",
    "c = 1.4\n",
    "v = 0.2    #noise variance\n",
    "range_min = 0    #min value of X\n",
    "range_max = 20    #max value of X\n",
    "dataset_size = 1000    #dataset size\n",
    "\n",
    "\n",
    "\n",
    "#-----FedAVG Parameters\n",
    "learning_rate = 1e-4\n",
    "local_epochs = 200\n",
    "lr_gamma_FedREG = 1\n",
    "lr_gamma_FedAVG = 0.7\n",
    "\n",
    "\n",
    "#-----Execution Parameters\n",
    "iterations = 3\n",
    "train_percentage = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def synthetic_dataset_creator(multi_features=False):\n",
    "    \n",
    "    if multi_features is True:\n",
    "        \n",
    "        #dataset_X1 = np.linspace(range_min, range_max, dataset_size)\n",
    "        dataset_X1 = np.random.uniform(low=range_min, high=range_max, size=(dataset_size,))\n",
    "        #dataset_X2 = np.linspace(range_min, range_max, dataset_size)\n",
    "        dataset_X2 = np.random.uniform(low=range_min, high=range_max, size=(dataset_size,))\n",
    "        #dataset_X3 = np.linspace(range_min, range_max, dataset_size)\n",
    "        dataset_X3= np.random.uniform(low=range_min, high=range_max, size=(dataset_size,))\n",
    "\n",
    "        np.random.shuffle(dataset_X1)\n",
    "        np.random.shuffle(dataset_X2)\n",
    "        np.random.shuffle(dataset_X3)\n",
    "\n",
    "        dataset_X = np.array([dataset_X1, dataset_X2, dataset_X3])\n",
    "        dataset_y = dataset_X1 * m + dataset_X2 * m2 + dataset_X3 * m3 + c + np.random.randn(dataset_X1.size) * math.sqrt(v)\n",
    "        #dataset_y = m * np.sin(dataset_X1*(0.1*math.pi)+ dataset_X2*(0.1*math.pi) + dataset_X3*(0.1*math.pi)) + np.random.randn(dataset_X1.size) * math.sqrt(v)\n",
    "        dataset_y = dataset_y.reshape(-1,1)\n",
    "        dataset_X = dataset_X.transpose()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #dataset_X = np.linspace(range_min, range_max, dataset_size)\n",
    "        dataset_X = np.random.uniform(low=range_min, high=range_max, size=(dataset_size,))\n",
    "        np.random.shuffle(dataset_X)\n",
    "\n",
    "        #dataset_y =  dataset_X * m + c +  np.random.randn(dataset_X.size) * math.sqrt(v)\n",
    "        dataset_y = m * np.sin(dataset_X*(0.1*math.pi)) + np.random.randn(dataset_X.size) * math.sqrt(v)\n",
    "        \n",
    "        dataset_X = dataset_X.reshape(-1,1)\n",
    "        dataset_y = dataset_y.reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    train_X, test_X = np.split(dataset_X, \n",
    "                [int(train_percentage * len(dataset_X))\n",
    "                ])\n",
    "\n",
    "    train_y, test_y = np.split(dataset_y, \n",
    "                [int(train_percentage * len(dataset_y))\n",
    "                ])\n",
    "    \n",
    "    \n",
    "    train_list_X = splitDataset(train_X, num_workers, num_rounds)\n",
    "    train_list_y = splitDataset(train_y, num_workers, num_rounds)\n",
    "    \n",
    "\n",
    "    for i in range(0, len(train_list_X)):\n",
    "        train_list_X[i] = torch.from_numpy(train_list_X[i])\n",
    "\n",
    "    for i in range(0, len(train_list_y)):\n",
    "        train_list_y[i] = torch.from_numpy(train_list_y[i])\n",
    "    \n",
    "    \n",
    "    return train_list_X, train_list_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Both the algorithms must start from the same weights.\n",
    "    Initialize both FedREG and FedAVG Neural Networks\n",
    "    w and w_avg are the lists of models\n",
    "'''\n",
    "\n",
    "def model_creator(input_size, output_size, hidden=10):\n",
    "    \n",
    "    w = []\n",
    "    w.append(customModel(input_size, output_size, H=hidden))\n",
    "    for i in range(1, num_workers):\n",
    "        w.append(copy.deepcopy(w[0]))\n",
    "    \n",
    "    w_avg = []\n",
    "    for i in range(0, num_workers):\n",
    "        w_avg.append(copy.deepcopy(w[0]))\n",
    "        \n",
    "    return w, w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_optimizer(models, gamma, decay=True):\n",
    "    \n",
    "    optimizers = []\n",
    "    criterion = []\n",
    "    \n",
    "    for i in models:\n",
    "        criterion.append(torch.nn.MSELoss()) \n",
    "        \n",
    "        if decay is True:\n",
    "            optimizers.append(torch.optim.lr_scheduler.StepLR(torch.optim.SGD(i.parameters(), lr=learning_rate),\n",
    "                                                          step_size = local_epochs,\n",
    "                                                          gamma=gamma))\n",
    "        else:    \n",
    "            optimizers.append(torch.optim.SGD(i.parameters(), lr=learning_rate))   \n",
    "    \n",
    "    return criterion, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_parameters(models_list):\n",
    "    \n",
    "    params = []\n",
    "    \n",
    "    for i in models_list:\n",
    "        params.append(list(i.parameters()))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, inputs, labels, local_epochs, decay):\n",
    "    \n",
    "    for epoch in range(local_epochs):\n",
    "        \n",
    "        if decay is True:\n",
    "            optimizer.optimizer.zero_grad()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "\n",
    "        for x in range(len(train_list_X[i*num_workers+j])):\n",
    "            input_ = (inputs[x]).float()\n",
    "            input_ = input_.unsqueeze(0)\n",
    "            label = (labels[x]).float()\n",
    "            label = label.unsqueeze(0)\n",
    "            y_pred = model(input_)\n",
    "            loss += criterion(y_pred, label)\n",
    "\n",
    "        # store loss info for current epoch \n",
    "        worker_losses_dict[j].append(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if decay is True:\n",
    "            optimizer.optimizer.step()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_params(models, params):\n",
    "    \n",
    "    new_params = []\n",
    "    \n",
    "    for param_i in range(len(params[0])):\n",
    "        spdz_params = list()\n",
    "\n",
    "        for remote_index in range(len(models)):\n",
    "            spdz_params.append(params[remote_index][param_i])\n",
    "\n",
    "        spdz = torch.tensor([0.0]).float()\n",
    "\n",
    "        for k in spdz_params:\n",
    "            spdz = spdz + k\n",
    "\n",
    "        new_param = (spdz)\n",
    "        new_params.append(new_param)\n",
    "    \n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FedREG_params(global_params, new_params):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(global_params)):\n",
    "            for j in range(len(global_params[i])):\n",
    "                global_params[i][j] = ((c * global_params[i][j] + new_params[i][j]) / (c + len(w))).data.detach().clone()\n",
    "    \n",
    "    return global_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FedAVG_params(models, params):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        new_params = []\n",
    "\n",
    "        for param_i in range(len(params[0])):\n",
    "\n",
    "            spdz_params = []\n",
    "\n",
    "            for remote_index in range(len(models)):\n",
    "                spdz_params.append(params[remote_index][param_i])\n",
    "\n",
    "            spdz = torch.tensor([0.0]).float()\n",
    "\n",
    "            for k in spdz_params:\n",
    "                spdz = spdz + k\n",
    "\n",
    "            new_param = (spdz) / len(models)\n",
    "            new_params.append(new_param)\n",
    "    \n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(new, models):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for remote_index in range(len(models)):\n",
    "            param_index = 0\n",
    "\n",
    "            for p in models[remote_index].parameters():\n",
    "                p.data = new[param_index].data.detach().clone()\n",
    "                param_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lists to keep track of the losses and scores during multiple iterations\n",
    "\n",
    "def single_iteration(seed):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #setting the current seed\n",
    "    set_new_seed(seed)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #-----Federated Parameters\n",
    "    num_workers = 3\n",
    "    num_rounds = 4\n",
    "\n",
    "\n",
    "    #-----Linear Regression Parameters\n",
    "    m = -2.1\n",
    "    m2 = 1.4\n",
    "    m3 = -0.5\n",
    "    c = 1.4\n",
    "    v = 0.2    #noise variance\n",
    "    range_min = 0    #min value of X\n",
    "    range_max = 20    #max value of X\n",
    "    dataset_size = 100    #dataset size\n",
    "\n",
    "\n",
    "\n",
    "    #-----FedAVG Parameters\n",
    "    learning_rate = 1e-4\n",
    "    local_epochs = 100\n",
    "    lr_gamma_FedREG = 1\n",
    "    lr_gamma_FedAVG = 0.7\n",
    "\n",
    "\n",
    "    #-----Execution Parameters\n",
    "    iterations = 4\n",
    "    train_percentage = 0.8\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Dataset Creation\n",
    "    \n",
    "    train_list_X, train_list_y, test_X, test_y = synthetic_dataset_creator(multi_features=False)\n",
    "    \n",
    "    \n",
    "    w, w_avg = model_creator(   input_size=len(train_list_X[0][0]), \n",
    "                                output_size=len(train_list_y[0][0]), \n",
    "                                hidden=64\n",
    "                            )\n",
    "\n",
    "    criterion, optimizers = loss_optimizer(models=w, gamma=lr_gamma_FedREG, decay=False)\n",
    "    \n",
    "        \n",
    "    params = get_models_parameters(models_list=w)\n",
    "        \n",
    "        \n",
    "    for model in w:\n",
    "        model.train()\n",
    "\n",
    "\n",
    "    # stores losses trend for each worker along epochs\n",
    "    worker_losses_dict = defaultdict(list)\n",
    "\n",
    "    error = []\n",
    "    score = []\n",
    "\n",
    "\n",
    "    ### OUR ALGORITHM - EXECUTION\n",
    "    \n",
    "    # Parameter 'c' of FedREG algorithm\n",
    "    c = 0\n",
    "    \n",
    "    # global parameter initialization\n",
    "    # Fill for the first time the global_params list. \n",
    "    # If NN are initialized with the same weights,\n",
    "    # the averaging operation returns the same parameters.\n",
    "    global_params = calculate_FedAVG_params(w, params)\n",
    "    \n",
    "    \n",
    "    # EXECUTION\n",
    "    for i in range(0, num_rounds):\n",
    "\n",
    "        print(\"---------- ROUND N° {}\".format(i+1))\n",
    "\n",
    "        for j in range(0, num_workers):\n",
    "            train(  model=w[j],\n",
    "                    optimizer=optimizers[j],\n",
    "                    criterion=criterion[j],\n",
    "                    inputs=train_list_X[i*num_workers+j],\n",
    "                    labels=train_list_y[i*num_workers+j],\n",
    "                    local_epochs=local_epochs,\n",
    "                    decay=False)\n",
    "        \n",
    "            \n",
    "        # Get the params\n",
    "        params = get_models_parameters(w)\n",
    "        \n",
    "        \n",
    "        # Parameter Aggregation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            new_params = sum_of_params(w, params)\n",
    "            \n",
    "            # Calculate the aggregated parameters with our method\n",
    "            global_params = calculate_FedREG_params(global_params, new_params)\n",
    "            \n",
    "            # Set new aggregated parameters\n",
    "            set_parameters(global_params, w)\n",
    "        \n",
    "        \n",
    "            # Perform the prediction\n",
    "            predicted = w[0](Variable(torch.from_numpy(test_X).float())).data.numpy()\n",
    "\n",
    "            error.append(mean_squared_error(test_y, predicted))\n",
    "            score.append(r2_score(test_y, predicted))\n",
    "        \n",
    "        # Update parameter C\n",
    "        c = c + len(w)\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "    ### -----------------------------------------------------------------------\n",
    "    ### -----------------------------------------------------------------------\n",
    "    ### -----------------------------------------------------------------------\n",
    "    ### -----------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"--------------- FED AVG ----------------\")\n",
    "\n",
    "    \n",
    "    ### FEDAVG - INITIALIZATION\n",
    "    \n",
    "    criterion_avg, optimizers_avg = loss_optimizer(models=w_avg, gamma=lr_gamma_FedAVG, decay=True)\n",
    "    \n",
    "        \n",
    "    params = get_models_parameters(w_avg)\n",
    "        \n",
    "        \n",
    "    for model in w_avg:\n",
    "        model.train()\n",
    "    \n",
    "    # stores losses trend for each worker along epochs\n",
    "    worker_losses_dict = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    error_fedavg = []\n",
    "    score_fedavg = []\n",
    "\n",
    "    \n",
    "    ### FEDAVG - EXECUTION\n",
    "    \n",
    "\n",
    "    for i in range(0, num_rounds):\n",
    "        \n",
    "        print(\"---------- ROUND N° {}\".format(i+1))\n",
    "\n",
    "        for j in range(0, num_workers):\n",
    "            train(  model=w_avg[j],\n",
    "                    optimizer=optimizers_avg[j],\n",
    "                    criterion=criterion_avg[j],\n",
    "                    inputs=train_list_X[i*num_workers+j],\n",
    "                    labels=train_list_y[i*num_workers+j],\n",
    "                    local_epochs=local_epochs,\n",
    "                    decay=True)\n",
    "        \n",
    "            \n",
    "        # Get the params\n",
    "        params = get_models_parameters(w_avg)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            new_params = calculate_FedAVG_params(w_avg, params)\n",
    "\n",
    "            set_parameters(new_params, w_avg)\n",
    "\n",
    "            predicted = w_avg[0](Variable(torch.from_numpy(test_X).float())).data.numpy()\n",
    "            \n",
    "            error_fedavg.append(mean_squared_error(test_y, predicted))\n",
    "            score_fedavg.append(r2_score(test_y, predicted))\n",
    "        \n",
    "    return error, score, error_fedavg, score_fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- ROUND N° 1\n",
      "---------- ROUND N° 1\n",
      "---------- ROUND N° 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_list_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/alex/anaconda3/envs/tensorflow_cpu/lib/python3.6/concurrent/futures/process.py\", line 175, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/alex/anaconda3/envs/tensorflow_cpu/lib/python3.6/concurrent/futures/process.py\", line 153, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/alex/anaconda3/envs/tensorflow_cpu/lib/python3.6/concurrent/futures/process.py\", line 153, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"<ipython-input-15-671504d758c7>\", line 96, in single_iteration\n    decay=False)\n  File \"<ipython-input-10-4b5bd89425e5>\", line 12, in train\n    for x in range(len(train_list_X[i*num_workers+j])):\nNameError: name 'train_list_X' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-507d89d8827e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_fedavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_fedavg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEEDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0merror_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mscore_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_cpu/lib/python3.6/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \"\"\"\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_cpu/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_cpu/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_cpu/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_list_X' is not defined"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "SEEDS = np.linspace(1, iterations, iterations, dtype=int).tolist()\n",
    "\n",
    "error_list = []\n",
    "score_list = []\n",
    "error_list_fedavg = []\n",
    "score_list_fedavg = []\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
    "        for error, score, error_fedavg, score_fedavg in zip(executor.map(single_iteration, SEEDS)):\n",
    "            error_list.append(error)\n",
    "            score_list.append(score)\n",
    "            error_list_fedavg.append(error_fedavg)\n",
    "            score_list_fedavg.append(score_fedavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "err_std = []\n",
    "for i in range(0, len(error_list[0])):\n",
    "    s = 0\n",
    "    e = []\n",
    "    for k in error_list:\n",
    "        s += k[i]\n",
    "        e.append(k[i])\n",
    "    err.append(s / len(error_list))\n",
    "    err_std.append(np.std(e))\n",
    "\n",
    "sc = []\n",
    "sc_std = []\n",
    "for i in range(0, len(score_list[0])):\n",
    "    s = 0\n",
    "    e = []\n",
    "    for k in score_list:\n",
    "        s += k[i]\n",
    "        e.append(k[i])\n",
    "    sc.append(s / len(score_list))\n",
    "    sc_std.append(np.std(e))\n",
    "\n",
    "err_s = []\n",
    "err_s_std = []\n",
    "for i in range(0, len(error_list_fedavg[0])):\n",
    "    s = 0\n",
    "    e = []\n",
    "    for k in error_list_fedavg:\n",
    "        s += k[i]\n",
    "        e.append(k[i])\n",
    "    err_s.append(s / len(error_list_fedavg))\n",
    "    err_s_std.append(np.std(e))\n",
    "\n",
    "sc_s = []\n",
    "sc_s_std = []\n",
    "for i in range(0, len(score_list_fedavg[0])):\n",
    "    s = 0\n",
    "    e = []\n",
    "    for k in score_list_fedavg:\n",
    "        s += k[i]\n",
    "        e.append(k[i])\n",
    "    sc_s.append(s / len(score_list_fedavg))\n",
    "    sc_s_std.append(np.std(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,5))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5))\n",
    "fig.suptitle('Test 5')\n",
    "\n",
    "\n",
    "x = np.arange(num_rounds)\n",
    "\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "\n",
    "ax1.fill_between(x, np.array(err)+np.array(err_std), np.array(err)-np.array(err_std), color='red', label='FedREGRESSION', alpha=0.2)\n",
    "ax1.fill_between(x, np.array(err_s)+np.array(err_s_std), np.array(err_s)-np.array(err_s_std), color='blue', label='FedAVG', alpha=0.2)\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "ax1.set_xlabel(\"upper right\")\n",
    "ax1.set_ylabel(\"MSE\")\n",
    "\n",
    "\n",
    "\n",
    "ax2.fill_between(x, np.array(sc)+np.array(sc_std), np.array(sc)-np.array(sc_std), color='red', label='FedREGRESSION', alpha=0.2)\n",
    "ax2.fill_between(x, np.array(sc_s)+np.array(sc_s_std), np.array(sc_s)-np.array(sc_s_std), color='blue', label='FedAVG', alpha=0.2)\n",
    "\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "ax2.set_xlabel(\"Rounds\")\n",
    "ax2.set_ylabel(\"R2 Score\")\n",
    "\n",
    "#ax2.set_ylim(ymin=0.2, ymax=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.draw()\n",
    "\n",
    "plt.savefig(\"test.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_cpu)",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
