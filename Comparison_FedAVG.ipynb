{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFy3hJFsXOX5"
   },
   "source": [
    "# **Non-Stationary Federated Learning**\n",
    "\n",
    "\n",
    "\n",
    "*   Deep Learning Framework: **PyTorch**\n",
    "*   Dataset: **Synthetic**\n",
    "*   Workers: **4**\n",
    "*   Data Distribution: **IID on workers**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0sJeySKYBlR"
   },
   "source": [
    "## Importing libraries and setting parameters for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "KfKWG6_tehlh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from Stationary.core import *\n",
    "from Stationary.utils import *\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "nogg8QocIWSV"
   },
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "num_rounds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDBYhw7YYe8L"
   },
   "source": [
    "## Synthetic Dataset\n",
    "\n",
    "We create a synthetic dataset, reproducing a linear correlation between inputs and outputs, with the addition of a noise.\n",
    "\n",
    "Train set is divided into multiple slots, in order to reproduce the \"online\" approach: For each round, each worker has a different set for training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "V3RdoXlWdTBW"
   },
   "outputs": [],
   "source": [
    "# Linear Regression Coefficients\n",
    "m = 1.4\n",
    "c = 10\n",
    "\n",
    "dataset_X = np.linspace(0, 10, 300)\n",
    "np.random.shuffle(dataset_X)\n",
    "\n",
    "dataset_y =  dataset_X * m + c +  np.random.randn(dataset_X.size) * math.sqrt(3)\n",
    "\n",
    "dataset_X = dataset_X.reshape(-1,1)\n",
    "dataset_y = dataset_y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percentage = 0.9\n",
    "\n",
    "\n",
    "train_X, test_X = np.split(dataset_X, \n",
    "            [int(train_percentage * len(dataset_X))\n",
    "            ])\n",
    "\n",
    "train_y, test_y = np.split(dataset_y, \n",
    "            [int(train_percentage * len(dataset_y))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_X = splitDataset(train_X, num_workers, num_rounds)\n",
    "train_list_y = splitDataset(train_y, num_workers, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "_473clIBfBZr"
   },
   "outputs": [],
   "source": [
    "worker_list = []\n",
    "for i in range(0, num_workers):\n",
    "    worker_list.append(Worker(coef = np.zeros(shape=dataset_X[0].size), intercept = np.zeros(shape=1), model=linear_model.LinearRegression()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "I7Hl2nKMf1pE"
   },
   "outputs": [],
   "source": [
    "server = Server(coef = np.zeros(shape=dataset_X[0].size), intercept = np.zeros(shape=1), workers = worker_list, num_features = dataset_X[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "d7SHGYjggCNy",
    "outputId": "9b5edf52-f29d-46fe-f879-d53d2fe67d73",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ROUND 1------\n",
      "Mean squared error: 5.619\n",
      "Coefficient of determinaton: 0.575 \n",
      "\n",
      "------ROUND 2------\n",
      "Mean squared error: 3.022\n",
      "Coefficient of determinaton: 0.772 \n",
      "\n",
      "------ROUND 3------\n",
      "Mean squared error: 2.894\n",
      "Coefficient of determinaton: 0.781 \n",
      "\n",
      "------ROUND 4------\n",
      "Mean squared error: 2.860\n",
      "Coefficient of determinaton: 0.784 \n",
      "\n",
      "------ROUND 5------\n",
      "Mean squared error: 2.919\n",
      "Coefficient of determinaton: 0.779 \n",
      "\n",
      "------ROUND 6------\n",
      "Mean squared error: 2.881\n",
      "Coefficient of determinaton: 0.782 \n",
      "\n",
      "------ROUND 7------\n",
      "Mean squared error: 2.891\n",
      "Coefficient of determinaton: 0.782 \n",
      "\n",
      "------ROUND 8------\n",
      "Mean squared error: 3.037\n",
      "Coefficient of determinaton: 0.771 \n",
      "\n",
      "------ROUND 9------\n",
      "Mean squared error: 3.034\n",
      "Coefficient of determinaton: 0.771 \n",
      "\n",
      "------ROUND 10------\n",
      "Mean squared error: 2.985\n",
      "Coefficient of determinaton: 0.774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "score = []\n",
    "\n",
    "for i in range(0, num_rounds):\n",
    "    \n",
    "    for j in range(0, num_workers):\n",
    "        worker_list[j].train(X = train_list_X[i*num_workers+j] , y = train_list_y[i*num_workers+j])\n",
    "\n",
    "    server.aggregation() \n",
    "    server.return_to_workers()\n",
    "    \n",
    "    pred_server = server.evaluate(test_X)\n",
    "    print('------ROUND {}------'.format(i+1))\n",
    "    print('Mean squared error: %.3f' \n",
    "          % mean_squared_error(test_y, pred_server))\n",
    "    print('Coefficient of determinaton: %.3f \\n'\n",
    "          % r2_score(test_y, pred_server))\n",
    "    error.append(mean_squared_error(test_y, pred_server))\n",
    "    score.append(r2_score(test_y, pred_server))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(test_X, test_y, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(test_X, pred_server, '--', label='Predictions', alpha=0.8)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Averaging\n",
    "\n",
    "Implementation of FedAVG in PyTorch. \n",
    "\n",
    "First of all, the dataset is converted in tensors.\n",
    "Then, a model, a loss function and an optimizer are instantiated for each worker.\n",
    "Model parameters are averaged at each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "ZVqgQFEnf4CG"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for i in range(0, len(train_list_X)):\n",
    "    train_list_X[i] = torch.from_numpy(train_list_X[i])\n",
    "\n",
    "for i in range(0, len(train_list_y)):\n",
    "    train_list_y[i] = torch.from_numpy(train_list_y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "MGKvcoywMQkc"
   },
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        \n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize, bias=True)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.linear(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "-hLeUF7VMZBY"
   },
   "outputs": [],
   "source": [
    "w = []\n",
    "\n",
    "for i in range(0, num_workers):\n",
    "    \n",
    "    w.append(linearRegression(dataset_X[0].size, dataset_y[0].size))\n",
    "    w[i] = w[i].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "1pssyuTfNa5K"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "criterion = []\n",
    "optimizers = []\n",
    "\n",
    "for i in w:\n",
    "    \n",
    "    criterion.append(torch.nn.MSELoss()) \n",
    "    optimizers.append(torch.optim.SGD(i.parameters(), lr=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "\n",
    "\n",
    "for i in w:\n",
    "    params.append(list(i.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "3cH1HLJUBDyi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0,  Worker: 1 \n",
      "Epoch: 1,  Worker: 1 \n",
      "Epoch: 2,  Worker: 1 \n",
      "Epoch: 3,  Worker: 1 \n",
      "Epoch: 4,  Worker: 1 \n",
      "Epoch: 5,  Worker: 1 \n",
      "Epoch: 6,  Worker: 1 \n",
      "Epoch: 7,  Worker: 1 \n",
      "Epoch: 8,  Worker: 1 \n",
      "Epoch: 9,  Worker: 1 \n",
      "Epoch: 10,  Worker: 1 \n",
      "Epoch: 11,  Worker: 1 \n",
      "Epoch: 12,  Worker: 1 \n",
      "Epoch: 13,  Worker: 1 \n",
      "Epoch: 14,  Worker: 1 \n",
      "Epoch: 15,  Worker: 1 \n",
      "Epoch: 16,  Worker: 1 \n",
      "Epoch: 17,  Worker: 1 \n",
      "Epoch: 18,  Worker: 1 \n",
      "Epoch: 19,  Worker: 1 \n",
      "Epoch: 20,  Worker: 1 \n",
      "Epoch: 21,  Worker: 1 \n",
      "Epoch: 22,  Worker: 1 \n",
      "Epoch: 23,  Worker: 1 \n",
      "Epoch: 24,  Worker: 1 \n",
      "Epoch: 25,  Worker: 1 \n",
      "Epoch: 26,  Worker: 1 \n",
      "Epoch: 27,  Worker: 1 \n",
      "Epoch: 28,  Worker: 1 \n",
      "Epoch: 29,  Worker: 1 \n",
      "Epoch: 30,  Worker: 1 \n",
      "Epoch: 31,  Worker: 1 \n",
      "Epoch: 32,  Worker: 1 \n",
      "Epoch: 33,  Worker: 1 \n",
      "Epoch: 34,  Worker: 1 \n",
      "Epoch: 35,  Worker: 1 \n",
      "Epoch: 36,  Worker: 1 \n",
      "Epoch: 37,  Worker: 1 \n",
      "Epoch: 38,  Worker: 1 \n",
      "Epoch: 39,  Worker: 1 \n",
      "Epoch: 40,  Worker: 1 \n",
      "Epoch: 41,  Worker: 1 \n",
      "Epoch: 42,  Worker: 1 \n",
      "Epoch: 43,  Worker: 1 \n",
      "Epoch: 44,  Worker: 1 \n",
      "Epoch: 45,  Worker: 1 \n",
      "Epoch: 46,  Worker: 1 \n",
      "Epoch: 47,  Worker: 1 \n",
      "Epoch: 48,  Worker: 1 \n",
      "Epoch: 49,  Worker: 1 \n",
      "Epoch: 50,  Worker: 1 \n",
      "Epoch: 51,  Worker: 1 \n",
      "Epoch: 52,  Worker: 1 \n",
      "Epoch: 53,  Worker: 1 \n",
      "Epoch: 54,  Worker: 1 \n",
      "Epoch: 55,  Worker: 1 \n",
      "Epoch: 56,  Worker: 1 \n",
      "Epoch: 57,  Worker: 1 \n",
      "Epoch: 58,  Worker: 1 \n",
      "Epoch: 59,  Worker: 1 \n",
      "Epoch: 60,  Worker: 1 \n",
      "Epoch: 61,  Worker: 1 \n",
      "Epoch: 62,  Worker: 1 \n",
      "Epoch: 63,  Worker: 1 \n",
      "Epoch: 64,  Worker: 1 \n",
      "Epoch: 65,  Worker: 1 \n",
      "Epoch: 66,  Worker: 1 \n",
      "Epoch: 67,  Worker: 1 \n",
      "Epoch: 68,  Worker: 1 \n",
      "Epoch: 69,  Worker: 1 \n",
      "Epoch: 70,  Worker: 1 \n",
      "Epoch: 71,  Worker: 1 \n",
      "Epoch: 72,  Worker: 1 \n",
      "Epoch: 73,  Worker: 1 \n",
      "Epoch: 74,  Worker: 1 \n",
      "Epoch: 75,  Worker: 1 \n",
      "Epoch: 76,  Worker: 1 \n",
      "Epoch: 77,  Worker: 1 \n",
      "Epoch: 78,  Worker: 1 \n",
      "Epoch: 79,  Worker: 1 \n",
      "Epoch: 80,  Worker: 1 \n",
      "Epoch: 81,  Worker: 1 \n",
      "Epoch: 82,  Worker: 1 \n",
      "Epoch: 83,  Worker: 1 \n",
      "Epoch: 84,  Worker: 1 \n",
      "Epoch: 85,  Worker: 1 \n",
      "Epoch: 86,  Worker: 1 \n",
      "Epoch: 87,  Worker: 1 \n",
      "Epoch: 88,  Worker: 1 \n",
      "Epoch: 89,  Worker: 1 \n",
      "Epoch: 90,  Worker: 1 \n",
      "Epoch: 91,  Worker: 1 \n",
      "Epoch: 92,  Worker: 1 \n",
      "Epoch: 93,  Worker: 1 \n",
      "Epoch: 94,  Worker: 1 \n",
      "Epoch: 95,  Worker: 1 \n",
      "Epoch: 96,  Worker: 1 \n",
      "Epoch: 97,  Worker: 1 \n",
      "Epoch: 98,  Worker: 1 \n",
      "Epoch: 99,  Worker: 1 \n",
      "Epoch: 0,  Worker: 2 \n",
      "Epoch: 1,  Worker: 2 \n",
      "Epoch: 2,  Worker: 2 \n",
      "Epoch: 3,  Worker: 2 \n",
      "Epoch: 4,  Worker: 2 \n",
      "Epoch: 5,  Worker: 2 \n",
      "Epoch: 6,  Worker: 2 \n",
      "Epoch: 7,  Worker: 2 \n",
      "Epoch: 8,  Worker: 2 \n",
      "Epoch: 9,  Worker: 2 \n",
      "Epoch: 10,  Worker: 2 \n",
      "Epoch: 11,  Worker: 2 \n",
      "Epoch: 12,  Worker: 2 \n",
      "Epoch: 13,  Worker: 2 \n",
      "Epoch: 14,  Worker: 2 \n",
      "Epoch: 15,  Worker: 2 \n",
      "Epoch: 16,  Worker: 2 \n",
      "Epoch: 17,  Worker: 2 \n",
      "Epoch: 18,  Worker: 2 \n",
      "Epoch: 19,  Worker: 2 \n",
      "Epoch: 20,  Worker: 2 \n",
      "Epoch: 21,  Worker: 2 \n",
      "Epoch: 22,  Worker: 2 \n",
      "Epoch: 23,  Worker: 2 \n",
      "Epoch: 24,  Worker: 2 \n",
      "Epoch: 25,  Worker: 2 \n",
      "Epoch: 26,  Worker: 2 \n",
      "Epoch: 27,  Worker: 2 \n",
      "Epoch: 28,  Worker: 2 \n",
      "Epoch: 29,  Worker: 2 \n",
      "Epoch: 30,  Worker: 2 \n",
      "Epoch: 31,  Worker: 2 \n",
      "Epoch: 32,  Worker: 2 \n",
      "Epoch: 33,  Worker: 2 \n",
      "Epoch: 34,  Worker: 2 \n",
      "Epoch: 35,  Worker: 2 \n",
      "Epoch: 36,  Worker: 2 \n",
      "Epoch: 37,  Worker: 2 \n",
      "Epoch: 38,  Worker: 2 \n",
      "Epoch: 39,  Worker: 2 \n",
      "Epoch: 40,  Worker: 2 \n",
      "Epoch: 41,  Worker: 2 \n",
      "Epoch: 42,  Worker: 2 \n",
      "Epoch: 43,  Worker: 2 \n",
      "Epoch: 44,  Worker: 2 \n",
      "Epoch: 45,  Worker: 2 \n",
      "Epoch: 46,  Worker: 2 \n",
      "Epoch: 47,  Worker: 2 \n",
      "Epoch: 48,  Worker: 2 \n",
      "Epoch: 49,  Worker: 2 \n",
      "Epoch: 50,  Worker: 2 \n",
      "Epoch: 51,  Worker: 2 \n",
      "Epoch: 52,  Worker: 2 \n",
      "Epoch: 53,  Worker: 2 \n",
      "Epoch: 54,  Worker: 2 \n",
      "Epoch: 55,  Worker: 2 \n",
      "Epoch: 56,  Worker: 2 \n",
      "Epoch: 57,  Worker: 2 \n",
      "Epoch: 58,  Worker: 2 \n",
      "Epoch: 59,  Worker: 2 \n",
      "Epoch: 60,  Worker: 2 \n",
      "Epoch: 61,  Worker: 2 \n",
      "Epoch: 62,  Worker: 2 \n",
      "Epoch: 63,  Worker: 2 \n",
      "Epoch: 64,  Worker: 2 \n",
      "Epoch: 65,  Worker: 2 \n",
      "Epoch: 66,  Worker: 2 \n",
      "Epoch: 67,  Worker: 2 \n",
      "Epoch: 68,  Worker: 2 \n",
      "Epoch: 69,  Worker: 2 \n",
      "Epoch: 70,  Worker: 2 \n",
      "Epoch: 71,  Worker: 2 \n",
      "Epoch: 72,  Worker: 2 \n",
      "Epoch: 73,  Worker: 2 \n",
      "Epoch: 74,  Worker: 2 \n",
      "Epoch: 75,  Worker: 2 \n",
      "Epoch: 76,  Worker: 2 \n",
      "Epoch: 77,  Worker: 2 \n",
      "Epoch: 78,  Worker: 2 \n",
      "Epoch: 79,  Worker: 2 \n",
      "Epoch: 80,  Worker: 2 \n",
      "Epoch: 81,  Worker: 2 \n",
      "Epoch: 82,  Worker: 2 \n",
      "Epoch: 83,  Worker: 2 \n",
      "Epoch: 84,  Worker: 2 \n",
      "Epoch: 85,  Worker: 2 \n",
      "Epoch: 86,  Worker: 2 \n",
      "Epoch: 87,  Worker: 2 \n",
      "Epoch: 88,  Worker: 2 \n",
      "Epoch: 89,  Worker: 2 \n",
      "Epoch: 90,  Worker: 2 \n",
      "Epoch: 91,  Worker: 2 \n",
      "Epoch: 92,  Worker: 2 \n",
      "Epoch: 93,  Worker: 2 \n",
      "Epoch: 94,  Worker: 2 \n",
      "Epoch: 95,  Worker: 2 \n",
      "Epoch: 96,  Worker: 2 \n",
      "Epoch: 97,  Worker: 2 \n",
      "Epoch: 98,  Worker: 2 \n",
      "Epoch: 99,  Worker: 2 \n",
      "Epoch: 0,  Worker: 3 \n",
      "Epoch: 1,  Worker: 3 \n",
      "Epoch: 2,  Worker: 3 \n",
      "Epoch: 3,  Worker: 3 \n",
      "Epoch: 4,  Worker: 3 \n",
      "Epoch: 5,  Worker: 3 \n",
      "Epoch: 6,  Worker: 3 \n",
      "Epoch: 7,  Worker: 3 \n",
      "Epoch: 8,  Worker: 3 \n",
      "Epoch: 9,  Worker: 3 \n",
      "Epoch: 10,  Worker: 3 \n",
      "Epoch: 11,  Worker: 3 \n",
      "Epoch: 12,  Worker: 3 \n",
      "Epoch: 13,  Worker: 3 \n",
      "Epoch: 14,  Worker: 3 \n",
      "Epoch: 15,  Worker: 3 \n",
      "Epoch: 16,  Worker: 3 \n",
      "Epoch: 17,  Worker: 3 \n",
      "Epoch: 18,  Worker: 3 \n",
      "Epoch: 19,  Worker: 3 \n",
      "Epoch: 20,  Worker: 3 \n",
      "Epoch: 21,  Worker: 3 \n",
      "Epoch: 22,  Worker: 3 \n",
      "Epoch: 23,  Worker: 3 \n",
      "Epoch: 24,  Worker: 3 \n",
      "Epoch: 25,  Worker: 3 \n",
      "Epoch: 26,  Worker: 3 \n",
      "Epoch: 27,  Worker: 3 \n",
      "Epoch: 28,  Worker: 3 \n",
      "Epoch: 29,  Worker: 3 \n",
      "Epoch: 30,  Worker: 3 \n",
      "Epoch: 31,  Worker: 3 \n",
      "Epoch: 32,  Worker: 3 \n",
      "Epoch: 33,  Worker: 3 \n",
      "Epoch: 34,  Worker: 3 \n",
      "Epoch: 35,  Worker: 3 \n",
      "Epoch: 36,  Worker: 3 \n",
      "Epoch: 37,  Worker: 3 \n",
      "Epoch: 38,  Worker: 3 \n",
      "Epoch: 39,  Worker: 3 \n",
      "Epoch: 40,  Worker: 3 \n",
      "Epoch: 41,  Worker: 3 \n",
      "Epoch: 42,  Worker: 3 \n",
      "Epoch: 43,  Worker: 3 \n",
      "Epoch: 44,  Worker: 3 \n",
      "Epoch: 45,  Worker: 3 \n",
      "Epoch: 46,  Worker: 3 \n",
      "Epoch: 47,  Worker: 3 \n",
      "Epoch: 48,  Worker: 3 \n",
      "Epoch: 49,  Worker: 3 \n",
      "Epoch: 50,  Worker: 3 \n",
      "Epoch: 51,  Worker: 3 \n",
      "Epoch: 52,  Worker: 3 \n",
      "Epoch: 53,  Worker: 3 \n",
      "Epoch: 54,  Worker: 3 \n",
      "Epoch: 55,  Worker: 3 \n",
      "Epoch: 56,  Worker: 3 \n",
      "Epoch: 57,  Worker: 3 \n",
      "Epoch: 58,  Worker: 3 \n",
      "Epoch: 59,  Worker: 3 \n",
      "Epoch: 60,  Worker: 3 \n",
      "Epoch: 61,  Worker: 3 \n",
      "Epoch: 62,  Worker: 3 \n",
      "Epoch: 63,  Worker: 3 \n",
      "Epoch: 64,  Worker: 3 \n",
      "Epoch: 65,  Worker: 3 \n",
      "Epoch: 66,  Worker: 3 \n",
      "Epoch: 67,  Worker: 3 \n",
      "Epoch: 68,  Worker: 3 \n",
      "Epoch: 69,  Worker: 3 \n",
      "Epoch: 70,  Worker: 3 \n",
      "Epoch: 71,  Worker: 3 \n",
      "Epoch: 72,  Worker: 3 \n",
      "Epoch: 73,  Worker: 3 \n",
      "Epoch: 74,  Worker: 3 \n",
      "Epoch: 75,  Worker: 3 \n",
      "Epoch: 76,  Worker: 3 \n",
      "Epoch: 77,  Worker: 3 \n",
      "Epoch: 78,  Worker: 3 \n",
      "Epoch: 79,  Worker: 3 \n",
      "Epoch: 80,  Worker: 3 \n",
      "Epoch: 81,  Worker: 3 \n",
      "Epoch: 82,  Worker: 3 \n",
      "Epoch: 83,  Worker: 3 \n",
      "Epoch: 84,  Worker: 3 \n",
      "Epoch: 85,  Worker: 3 \n",
      "Epoch: 86,  Worker: 3 \n",
      "Epoch: 87,  Worker: 3 \n",
      "Epoch: 88,  Worker: 3 \n",
      "Epoch: 89,  Worker: 3 \n",
      "Epoch: 90,  Worker: 3 \n",
      "Epoch: 91,  Worker: 3 \n",
      "Epoch: 92,  Worker: 3 \n",
      "Epoch: 93,  Worker: 3 \n",
      "Epoch: 94,  Worker: 3 \n",
      "Epoch: 95,  Worker: 3 \n",
      "Epoch: 96,  Worker: 3 \n",
      "Epoch: 97,  Worker: 3 \n",
      "Epoch: 98,  Worker: 3 \n",
      "Epoch: 99,  Worker: 3 \n",
      "Epoch: 0,  Worker: 4 \n",
      "Epoch: 1,  Worker: 4 \n",
      "Epoch: 2,  Worker: 4 \n",
      "Epoch: 3,  Worker: 4 \n",
      "Epoch: 4,  Worker: 4 \n",
      "Epoch: 5,  Worker: 4 \n",
      "Epoch: 6,  Worker: 4 \n",
      "Epoch: 7,  Worker: 4 \n",
      "Epoch: 8,  Worker: 4 \n",
      "Epoch: 9,  Worker: 4 \n",
      "Epoch: 10,  Worker: 4 \n",
      "Epoch: 11,  Worker: 4 \n",
      "Epoch: 12,  Worker: 4 \n",
      "Epoch: 13,  Worker: 4 \n",
      "Epoch: 14,  Worker: 4 \n",
      "Epoch: 15,  Worker: 4 \n",
      "Epoch: 16,  Worker: 4 \n",
      "Epoch: 17,  Worker: 4 \n",
      "Epoch: 18,  Worker: 4 \n",
      "Epoch: 19,  Worker: 4 \n",
      "Epoch: 20,  Worker: 4 \n",
      "Epoch: 21,  Worker: 4 \n",
      "Epoch: 22,  Worker: 4 \n",
      "Epoch: 23,  Worker: 4 \n",
      "Epoch: 24,  Worker: 4 \n",
      "Epoch: 25,  Worker: 4 \n",
      "Epoch: 26,  Worker: 4 \n",
      "Epoch: 27,  Worker: 4 \n",
      "Epoch: 28,  Worker: 4 \n",
      "Epoch: 29,  Worker: 4 \n",
      "Epoch: 30,  Worker: 4 \n",
      "Epoch: 31,  Worker: 4 \n",
      "Epoch: 32,  Worker: 4 \n",
      "Epoch: 33,  Worker: 4 \n",
      "Epoch: 34,  Worker: 4 \n",
      "Epoch: 35,  Worker: 4 \n",
      "Epoch: 36,  Worker: 4 \n",
      "Epoch: 37,  Worker: 4 \n",
      "Epoch: 38,  Worker: 4 \n",
      "Epoch: 39,  Worker: 4 \n",
      "Epoch: 40,  Worker: 4 \n",
      "Epoch: 41,  Worker: 4 \n",
      "Epoch: 42,  Worker: 4 \n",
      "Epoch: 43,  Worker: 4 \n",
      "Epoch: 44,  Worker: 4 \n",
      "Epoch: 45,  Worker: 4 \n",
      "Epoch: 46,  Worker: 4 \n",
      "Epoch: 47,  Worker: 4 \n",
      "Epoch: 48,  Worker: 4 \n",
      "Epoch: 49,  Worker: 4 \n",
      "Epoch: 50,  Worker: 4 \n",
      "Epoch: 51,  Worker: 4 \n",
      "Epoch: 52,  Worker: 4 \n",
      "Epoch: 53,  Worker: 4 \n",
      "Epoch: 54,  Worker: 4 \n",
      "Epoch: 55,  Worker: 4 \n",
      "Epoch: 56,  Worker: 4 \n",
      "Epoch: 57,  Worker: 4 \n",
      "Epoch: 58,  Worker: 4 \n",
      "Epoch: 59,  Worker: 4 \n",
      "Epoch: 60,  Worker: 4 \n",
      "Epoch: 61,  Worker: 4 \n",
      "Epoch: 62,  Worker: 4 \n",
      "Epoch: 63,  Worker: 4 \n",
      "Epoch: 64,  Worker: 4 \n",
      "Epoch: 65,  Worker: 4 \n",
      "Epoch: 66,  Worker: 4 \n",
      "Epoch: 67,  Worker: 4 \n",
      "Epoch: 68,  Worker: 4 \n",
      "Epoch: 69,  Worker: 4 \n",
      "Epoch: 70,  Worker: 4 \n",
      "Epoch: 71,  Worker: 4 \n",
      "Epoch: 72,  Worker: 4 \n",
      "Epoch: 73,  Worker: 4 \n",
      "Epoch: 74,  Worker: 4 \n",
      "Epoch: 75,  Worker: 4 \n",
      "Epoch: 76,  Worker: 4 \n",
      "Epoch: 77,  Worker: 4 \n",
      "Epoch: 78,  Worker: 4 \n",
      "Epoch: 79,  Worker: 4 \n",
      "Epoch: 80,  Worker: 4 \n",
      "Epoch: 81,  Worker: 4 \n",
      "Epoch: 82,  Worker: 4 \n",
      "Epoch: 83,  Worker: 4 \n",
      "Epoch: 84,  Worker: 4 \n",
      "Epoch: 85,  Worker: 4 \n",
      "Epoch: 86,  Worker: 4 \n",
      "Epoch: 87,  Worker: 4 \n",
      "Epoch: 88,  Worker: 4 \n",
      "Epoch: 89,  Worker: 4 \n",
      "Epoch: 90,  Worker: 4 \n",
      "Epoch: 91,  Worker: 4 \n",
      "Epoch: 92,  Worker: 4 \n",
      "Epoch: 93,  Worker: 4 \n",
      "Epoch: 94,  Worker: 4 \n",
      "Epoch: 95,  Worker: 4 \n",
      "Epoch: 96,  Worker: 4 \n",
      "Epoch: 97,  Worker: 4 \n",
      "Epoch: 98,  Worker: 4 \n",
      "Epoch: 99,  Worker: 4 \n",
      "[[Parameter containing:\n",
      "tensor([[2.9495]], requires_grad=True), Parameter containing:\n",
      "tensor([0.8293], requires_grad=True)], [Parameter containing:\n",
      "tensor([[2.8262]], requires_grad=True), Parameter containing:\n",
      "tensor([1.3738], requires_grad=True)], [Parameter containing:\n",
      "tensor([[2.9159]], requires_grad=True), Parameter containing:\n",
      "tensor([1.1295], requires_grad=True)], [Parameter containing:\n",
      "tensor([[3.2705]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0557], requires_grad=True)]]\n",
      "Epoch: 0,  Worker: 1 \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1] doesn't match the broadcast shape [1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-5b4ce29e4b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {},  Worker: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnew_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1] doesn't match the broadcast shape [1, 1]"
     ]
    }
   ],
   "source": [
    "local_epochs = 100\n",
    "\n",
    "\n",
    "\n",
    "for model in w:\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "for i in range(num_rounds):\n",
    "\n",
    "    for j in range(0, num_workers):\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            \n",
    "            optimizers[j].zero_grad()\n",
    "            loss = 0\n",
    "            \n",
    "            for x in range(len(train_list_X[i*num_workers+j])):\n",
    "                inputs = (train_list_X[i*num_workers+j][x]).float()\n",
    "                labels = (train_list_y[i*num_workers+j][x]).float()\n",
    "                y_pred = w[j](inputs)\n",
    "                loss += criterion[j](y_pred, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            print(\"Epoch: {},  Worker: {} \".format(epoch, j+1))\n",
    "            optimizers[j].step()\n",
    " \n",
    "    new_params = list()\n",
    "\n",
    "    for param_i in range(len(params[0])):\n",
    "\n",
    "        spdz_params = list()\n",
    "\n",
    "        for remote_index in range(len(w)):\n",
    "            spdz_params.append(params[remote_index][param_i].data)\n",
    "        \n",
    "        new_param = (torch.stack(spdz_params, dim=0).sum(dim=0).sum(dim=0))/len(w)\n",
    "        new_params.append(new_param)\n",
    "    \n",
    "    print(params)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for model in params:\n",
    "            for param in model:\n",
    "                param *= 0\n",
    "        \n",
    "        for remote_index in range(len(w)):\n",
    "            for param_index in range(len(params[remote_index])):\n",
    "                params[remote_index][param_index].set_(new_params[param_index])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "8NjU8W7kRq9x",
    "outputId": "2e80487e-4d7e-40cb-d02f-c69ee19c6473"
   },
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad(): \n",
    "    predicted = w[0](Variable(torch.from_numpy(test_X).float())).data.numpy()\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(test_X, test_y, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(test_X, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NS-Env.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_cpu]",
   "language": "python",
   "name": "conda-env-tensorflow_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
